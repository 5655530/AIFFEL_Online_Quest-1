{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgJ89GaViuUwpSulne0Q5B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comandi1969/AIFFEL_Online_Quest/blob/main/%E2%80%8B%20ML_With_Python/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_%EB%85%B8%EB%93%9C5_%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCZovHJauBg4",
        "outputId": "2eef69a8-b1ca-415d-81e2-77e575151018"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((284, 30), (285, 30), (284,), (285,))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# 데이터 로드\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "def make_dataset():\n",
        "    bc = load_breast_cancer()\n",
        "    df = pd.DataFrame(bc.data, columns=bc.feature_names)\n",
        "    df['target'] = bc.target\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df.drop('target', axis=1), df['target'], test_size=0.5, random_state=1004)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = make_dataset()\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q. 의사결정나무의 하이퍼파라미터 값을 조절해 보세요.\n",
        "# 주피터 노트북에서 실습해 보세요.\n",
        "# 디폴트값\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(\n",
        "    criterion = 'gini',\n",
        "    max_depth = None,\n",
        "    min_samples_split = 2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test, pred)\n",
        "# 0.9263157894736842"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI_7GC2fu-Hw",
        "outputId": "95ae55e9-448d-4d40-de23-3a7a98c804ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9263157894736842"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q. 의사결정나무의 하이퍼파라미터 값을 조절해 보세요.\n",
        "# 주피터 노트북에서 실습해 보세요.\n",
        "# 튜닝\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(\n",
        "    criterion = 'entropy',\n",
        "    max_depth = 4,\n",
        "    min_samples_split = 5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test, pred)\n",
        "# 0.9403508771929825"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O53oUqQnvmag",
        "outputId": "3b1c674b-8c62-4137-d5df-55364be821ba"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9403508771929825"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q. 랜덤포레스트의 하이퍼파라미터 값을 조절해 보세요.\n",
        "# 주피터 노트북에서 실습해 보세요.\n",
        "# 기본값\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    criterion = 'gini',\n",
        "    max_depth = None,\n",
        "    min_samples_split = 2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test, pred)\n",
        "# 0.9438596491228071"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9B8hWR-5Fjg",
        "outputId": "b182f215-ef46-4069-e1b0-d899a1600dc1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9438596491228071"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q. 랜덤포레스트의 하이퍼파라미터 값을 조절해 보세요.\n",
        "# 주피터 노트북에서 실습해 보세요.\n",
        "# 튜닝\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    criterion = 'entropy',\n",
        "    max_depth = 5,\n",
        "    min_samples_split = 5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test, pred)\n",
        "# 0.9473684210526315\n",
        "# 0.9508771929824561"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdByByap9M03",
        "outputId": "11d3f61d-71f7-4e0b-ea36-efafb1f7cf5b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9508771929824561"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q. xgboost의 하이퍼파라미터 값을 조절해 보세요.\n",
        "# 주피터 노트북에서 실습해 보세요.\n",
        "# 기본값\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(random_state=0, eval_metric='logloss',\n",
        "                      booster = 'gbtree',\n",
        "                      objective = 'binary:logistic',\n",
        "                      max_depth = 6,\n",
        "                      learning_rate = 0.1,\n",
        "                      n_estimators = 100,\n",
        "                      subsample = 1,\n",
        "                      colsample_bytree = 1,\n",
        "                      n_jobs = -1\n",
        "\n",
        "# xgboost 하이퍼파라미터\n",
        "# - booster(기본값 gbtree): 부스팅 알고리즘 (또는 dart, gblinear)\n",
        "# - objective(기본값 binary:logistic): 이진분류 (다중분류: multi:softmax)\n",
        "# - max_depth(기본값 6): 최대 한도 깊이\n",
        "# - learning_rate(기본값 0.1): 학습률\n",
        "# - n_estimators(기본값 100): 트리의 수\n",
        "# - subsample(기본값 1): 훈련 샘플 개수의 비율\n",
        "# - colsample_bytree(기본값 1): 특성 개수의 비율\n",
        "# - n_jobs(기본값 1): 사용 코어 수 (-1: 모든 코어를 다 사용)\n",
        "                     )\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test, pred)\n",
        "\n",
        "# 0.9614035087719298"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_gjjo2ZFp4F",
        "outputId": "b79c7789-d1d2-41df-bfec-1b8c428077f5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9614035087719298"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q. xgboost의 하이퍼파라미터 값을 조절해 보세요.\n",
        "# 주피터 노트북에서 실습해 보세요.\n",
        "# 튜닝\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(random_state=0,\n",
        "                      eval_metric='logloss',\n",
        "                      booster = 'gbtree',\n",
        "                      objective = 'binary:logistic',\n",
        "                      max_depth = 5,\n",
        "                      learning_rate = 0.05,\n",
        "                      n_estimators = 500,\n",
        "                      subsample = 1,\n",
        "                      colsample_bytree = 1,\n",
        "                      n_jobs = -1\n",
        "                      )\n",
        "\n",
        "# xgboost 하이퍼파라미터\n",
        "# - booster(기본값 gbtree): 부스팅 알고리즘 (또는 dart, gblinear)\n",
        "# - objective(기본값 binary:logistic): 이진분류 (다중분류: multi:softmax)\n",
        "# - max_depth(기본값 6): 최대 한도 깊이\n",
        "# - learning_rate(기본값 0.1): 학습률\n",
        "# - n_estimators(기본값 100): 트리의 수\n",
        "# - subsample(기본값 1): 훈련 샘플 개수의 비율\n",
        "# - colsample_bytree(기본값 1): 특성 개수의 비율\n",
        "# - n_jobs(기본값 1): 사용 코어 수 (-1: 모든 코어를 다 사용)\n",
        "\n",
        "#eval_set = [(X_test, y_test)]\n",
        "#model.fit(X_train, y_train, eval_set=eval_set) # early_stopping_rounds=10 미지정, 500번 학습\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test, pred)\n",
        "# 0.9649122807017544"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aELnnLWxGLoR",
        "outputId": "9d60b7aa-5343-4d5b-ff20-b8467d1b056c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9649122807017544"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 조기종료\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(random_state=0,\n",
        "                      eval_metric='logloss',\n",
        "                      booster = 'gbtree',\n",
        "                      objective = 'binary:logistic',\n",
        "                      max_depth = 5,\n",
        "                      learning_rate = 0.05,\n",
        "                      n_estimators = 500,\n",
        "                      subsample = 1,\n",
        "                      colsample_bytree = 1,\n",
        "                      n_jobs = -1\n",
        "                      )\n",
        "eval_set = [(X_test, y_test)]\n",
        "model.fit(X_train, y_train, eval_set=eval_set, early_stopping_rounds=10) # early_stopping_rounds=10 지정\n",
        "pred = model.predict(X_test)\n",
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_F7WLDmHg9X",
        "outputId": "e4a5aa23-d800-4a43-deb5-4eea26462c6b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.65391\n",
            "[1]\tvalidation_0-logloss:0.61861\n",
            "[2]\tvalidation_0-logloss:0.58697\n",
            "[3]\tvalidation_0-logloss:0.55756\n",
            "[4]\tvalidation_0-logloss:0.53038\n",
            "[5]\tvalidation_0-logloss:0.50611\n",
            "[6]\tvalidation_0-logloss:0.48363\n",
            "[7]\tvalidation_0-logloss:0.46304\n",
            "[8]\tvalidation_0-logloss:0.44332\n",
            "[9]\tvalidation_0-logloss:0.42512\n",
            "[10]\tvalidation_0-logloss:0.40821\n",
            "[11]\tvalidation_0-logloss:0.39260\n",
            "[12]\tvalidation_0-logloss:0.37838\n",
            "[13]\tvalidation_0-logloss:0.36512\n",
            "[14]\tvalidation_0-logloss:0.35276\n",
            "[15]\tvalidation_0-logloss:0.34090\n",
            "[16]\tvalidation_0-logloss:0.33018\n",
            "[17]\tvalidation_0-logloss:0.31967\n",
            "[18]\tvalidation_0-logloss:0.30997\n",
            "[19]\tvalidation_0-logloss:0.30105\n",
            "[20]\tvalidation_0-logloss:0.29259\n",
            "[21]\tvalidation_0-logloss:0.28478\n",
            "[22]\tvalidation_0-logloss:0.27725\n",
            "[23]\tvalidation_0-logloss:0.27027\n",
            "[24]\tvalidation_0-logloss:0.26358\n",
            "[25]\tvalidation_0-logloss:0.25755\n",
            "[26]\tvalidation_0-logloss:0.25139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[27]\tvalidation_0-logloss:0.24593\n",
            "[28]\tvalidation_0-logloss:0.24103\n",
            "[29]\tvalidation_0-logloss:0.23648\n",
            "[30]\tvalidation_0-logloss:0.23197\n",
            "[31]\tvalidation_0-logloss:0.22778\n",
            "[32]\tvalidation_0-logloss:0.22354\n",
            "[33]\tvalidation_0-logloss:0.21985\n",
            "[34]\tvalidation_0-logloss:0.21678\n",
            "[35]\tvalidation_0-logloss:0.21353\n",
            "[36]\tvalidation_0-logloss:0.21061\n",
            "[37]\tvalidation_0-logloss:0.20800\n",
            "[38]\tvalidation_0-logloss:0.20558\n",
            "[39]\tvalidation_0-logloss:0.20268\n",
            "[40]\tvalidation_0-logloss:0.20042\n",
            "[41]\tvalidation_0-logloss:0.19771\n",
            "[42]\tvalidation_0-logloss:0.19510\n",
            "[43]\tvalidation_0-logloss:0.19354\n",
            "[44]\tvalidation_0-logloss:0.19128\n",
            "[45]\tvalidation_0-logloss:0.18976\n",
            "[46]\tvalidation_0-logloss:0.18854\n",
            "[47]\tvalidation_0-logloss:0.18668\n",
            "[48]\tvalidation_0-logloss:0.18535\n",
            "[49]\tvalidation_0-logloss:0.18346\n",
            "[50]\tvalidation_0-logloss:0.18234\n",
            "[51]\tvalidation_0-logloss:0.18057\n",
            "[52]\tvalidation_0-logloss:0.17897\n",
            "[53]\tvalidation_0-logloss:0.17815\n",
            "[54]\tvalidation_0-logloss:0.17703\n",
            "[55]\tvalidation_0-logloss:0.17564\n",
            "[56]\tvalidation_0-logloss:0.17445\n",
            "[57]\tvalidation_0-logloss:0.17335\n",
            "[58]\tvalidation_0-logloss:0.17179\n",
            "[59]\tvalidation_0-logloss:0.17106\n",
            "[60]\tvalidation_0-logloss:0.17022\n",
            "[61]\tvalidation_0-logloss:0.16983\n",
            "[62]\tvalidation_0-logloss:0.16899\n",
            "[63]\tvalidation_0-logloss:0.16851\n",
            "[64]\tvalidation_0-logloss:0.16776\n",
            "[65]\tvalidation_0-logloss:0.16681\n",
            "[66]\tvalidation_0-logloss:0.16665\n",
            "[67]\tvalidation_0-logloss:0.16632\n",
            "[68]\tvalidation_0-logloss:0.16533\n",
            "[69]\tvalidation_0-logloss:0.16539\n",
            "[70]\tvalidation_0-logloss:0.16520\n",
            "[71]\tvalidation_0-logloss:0.16446\n",
            "[72]\tvalidation_0-logloss:0.16443\n",
            "[73]\tvalidation_0-logloss:0.16449\n",
            "[74]\tvalidation_0-logloss:0.16469\n",
            "[75]\tvalidation_0-logloss:0.16493\n",
            "[76]\tvalidation_0-logloss:0.16526\n",
            "[77]\tvalidation_0-logloss:0.16542\n",
            "[78]\tvalidation_0-logloss:0.16545\n",
            "[79]\tvalidation_0-logloss:0.16448\n",
            "[80]\tvalidation_0-logloss:0.16470\n",
            "[81]\tvalidation_0-logloss:0.16494\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9473684210526315"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ]
}