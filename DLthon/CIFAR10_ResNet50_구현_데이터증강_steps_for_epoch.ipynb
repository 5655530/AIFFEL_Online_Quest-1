{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comandi1969/AIFFEL_Online_Quest/blob/main/DLthon/CIFAR10_ResNet50_%EA%B5%AC%ED%98%84_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%A6%9D%EA%B0%95_steps_for_epoch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibc0aIvUi_MG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Add\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 데이터 로딩 및 전처리\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# 클래스 레이블을 원핫인코딩으로 변환\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "num_classes = 10  # CIFAR-10은 10개의 클래스로 구성됨\n",
        "y_train_one_hot = to_categorical(y_train, num_classes)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3IkPEUT6dWD"
      },
      "outputs": [],
      "source": [
        "# 이미지 데이터 증강\n",
        "# ImageDataGenerator를 사용하여 이미지 데이터 증강을 적용하면 모델의 과적합을 줄이고 일반화 성능을 향상시킬 수 있습니다.\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,       # 이미지 회전 범위 (도)\n",
        "    width_shift_range=0.1,  # 수평 방향으로 이동 범위 (전체 너비의 비율)\n",
        "    height_shift_range=0.1, # 수직 방향으로 이동 범위 (전체 높이의 비율)\n",
        "    shear_range=0.1,        # 전단 변환 범위\n",
        "    zoom_range=0.1,         # 확대/축소 범위\n",
        "    horizontal_flip=True,   # 수평 방향으로 뒤집기\n",
        "    vertical_flip=False,   # 수직 방향으로 뒤집기\n",
        "    fill_mode='nearest'     # 빈 공간을 어떻게 채울지 ('nearest', 'constant', 'reflect', 'wrap' 중 선택)\n",
        ")\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbJBpaoR6dWF"
      },
      "outputs": [],
      "source": [
        "# 로그 디렉터리 설정, 콜백함수 정의\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "import os\n",
        "\n",
        "log_dir = \"./logs\"\n",
        "if not os.path.exists(log_dir):\n",
        "    os.mkdir(log_dir)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * 0.95  # decrease the learning rate after 10 epochs\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "checkpoint = ModelCheckpoint('cifar10_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "lr_scheduler = LearningRateScheduler(scheduler, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT-YyMjcjxe4"
      },
      "outputs": [],
      "source": [
        "def identity_block(X, filters):\n",
        "    F1, F2, F3 = filters\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component\n",
        "    X = Conv2D(F1, (1, 1), padding='valid')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = ReLU()(X)\n",
        "\n",
        "    # Second component\n",
        "    X = Conv2D(F2, (3, 3), padding='same')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = ReLU()(X)\n",
        "\n",
        "    # Third component\n",
        "    X = Conv2D(F3, (1, 1), padding='valid')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "\n",
        "    # Add shortcut value\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = ReLU()(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def convolutional_block(X, filters, s=2):\n",
        "    F1, F2, F3 = filters\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component\n",
        "    X = Conv2D(F1, (1, 1), strides=(s, s), padding='valid')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = ReLU()(X)\n",
        "\n",
        "    # Second component\n",
        "    X = Conv2D(F2, (3, 3), padding='same')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = ReLU()(X)\n",
        "\n",
        "    # Third component\n",
        "    X = Conv2D(F3, (1, 1), padding='valid')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "\n",
        "    # Shortcut path\n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides=(s, s), padding='valid')(X_shortcut)\n",
        "    X_shortcut = BatchNormalization()(X_shortcut)\n",
        "\n",
        "    # Add shortcut value\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = ReLU()(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def ResNet50_CIFAR10(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolution\n",
        "    X = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(inputs)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = ReLU()(X)\n",
        "\n",
        "    # ResNet blocks\n",
        "    X = convolutional_block(X, [64, 64, 256], s=1)\n",
        "    X = identity_block(X, [64, 64, 256])\n",
        "    X = identity_block(X, [64, 64, 256])\n",
        "\n",
        "    X = convolutional_block(X, [128, 128, 512], s=2)\n",
        "    X = identity_block(X, [128, 128, 512])\n",
        "    X = identity_block(X, [128, 128, 512])\n",
        "\n",
        "    X = convolutional_block(X, [256, 256, 1024], s=2)\n",
        "    X = identity_block(X, [256, 256, 1024])\n",
        "    X = identity_block(X, [256, 256, 1024])\n",
        "\n",
        "    X = convolutional_block(X, [512, 512, 2048], s=2)\n",
        "    X = identity_block(X, [512, 512, 2048])\n",
        "    X = identity_block(X, [512, 512, 2048])\n",
        "\n",
        "    X = GlobalAveragePooling2D()(X)\n",
        "    outputs = Dense(num_classes, activation='softmax')(X)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwb9hzLNj2YF",
        "outputId": "fd511629-1ef2-472e-8e27-a3e3865c0106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 64)   1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 32, 32, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   4160        re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 64)   36928       re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 256)  16640       re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 256)  16640       re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 256)  0           batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 32, 32, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 64)   16448       re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 32, 32, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 64)   36928       re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 256)  16640       re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n",
            "                                                                 re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 32, 32, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 64)   16448       re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 64)   36928       re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 64)   256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, 32, 32, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 256)  16640       re_lu_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 256)  0           batch_normalization_10[0][0]     \n",
            "                                                                 re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_9 (ReLU)                  (None, 32, 32, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 128)  32896       re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_10 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_11 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 512)  66048       re_lu_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 512)  131584      re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 512)  2048        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 512)  0           batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_12 (ReLU)                 (None, 16, 16, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 128)  65664       re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_14 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 512)  66048       re_lu_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 512)  2048        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 512)  0           batch_normalization_17[0][0]     \n",
            "                                                                 re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_15 (ReLU)                 (None, 16, 16, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 128)  65664       re_lu_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 128)  512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_16 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_17 (ReLU)                 (None, 16, 16, 128)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 512)  66048       re_lu_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 512)  2048        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 512)  0           batch_normalization_20[0][0]     \n",
            "                                                                 re_lu_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_18 (ReLU)                 (None, 16, 16, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 256)    131328      re_lu_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 256)    1024        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_19 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 256)    590080      re_lu_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 256)    1024        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_20 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 1024)   263168      re_lu_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 8, 1024)   525312      re_lu_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 1024)   4096        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 8, 1024)   4096        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 1024)   0           batch_normalization_23[0][0]     \n",
            "                                                                 batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_21 (ReLU)                 (None, 8, 8, 1024)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 256)    262400      re_lu_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 8, 8, 256)    1024        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_22 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 256)    590080      re_lu_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 256)    1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_23 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 1024)   263168      re_lu_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 1024)   4096        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 1024)   0           batch_normalization_27[0][0]     \n",
            "                                                                 re_lu_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_24 (ReLU)                 (None, 8, 8, 1024)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 256)    262400      re_lu_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 256)    1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_25 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 256)    590080      re_lu_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 256)    1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_26 (ReLU)                 (None, 8, 8, 256)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 1024)   263168      re_lu_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 1024)   4096        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 1024)   0           batch_normalization_30[0][0]     \n",
            "                                                                 re_lu_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_27 (ReLU)                 (None, 8, 8, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 4, 4, 512)    524800      re_lu_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 4, 4, 512)    2048        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_28 (ReLU)                 (None, 4, 4, 512)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 4, 4, 512)    2359808     re_lu_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 4, 4, 512)    2048        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_29 (ReLU)                 (None, 4, 4, 512)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 4, 4, 2048)   1050624     re_lu_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 4, 4, 2048)   2099200     re_lu_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 4, 4, 2048)   8192        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 4, 4, 2048)   8192        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 4, 4, 2048)   0           batch_normalization_33[0][0]     \n",
            "                                                                 batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_30 (ReLU)                 (None, 4, 4, 2048)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 4, 4, 512)    1049088     re_lu_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 4, 4, 512)    2048        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_31 (ReLU)                 (None, 4, 4, 512)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 4, 4, 512)    2359808     re_lu_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 4, 4, 512)    2048        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_32 (ReLU)                 (None, 4, 4, 512)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 4, 4, 2048)   1050624     re_lu_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 4, 4, 2048)   8192        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 4, 4, 2048)   0           batch_normalization_37[0][0]     \n",
            "                                                                 re_lu_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_33 (ReLU)                 (None, 4, 4, 2048)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 4, 4, 512)    1049088     re_lu_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 4, 4, 512)    2048        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_34 (ReLU)                 (None, 4, 4, 512)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 4, 4, 512)    2359808     re_lu_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 512)    2048        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_35 (ReLU)                 (None, 4, 4, 512)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 2048)   1050624     re_lu_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 2048)   8192        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 4, 4, 2048)   0           batch_normalization_40[0][0]     \n",
            "                                                                 re_lu_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_36 (ReLU)                 (None, 4, 4, 2048)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           re_lu_36[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           20490       global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 19,952,778\n",
            "Trainable params: 19,910,410\n",
            "Non-trainable params: 42,368\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "780/780 [==============================] - 95s 112ms/step - loss: 1.8245 - accuracy: 0.3819 - val_loss: 2.5626 - val_accuracy: 0.3421\n",
            "Epoch 2/200\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 1.3234 - accuracy: 0.5379 - val_loss: 2.1610 - val_accuracy: 0.4184\n",
            "Epoch 3/200\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 1.1120 - accuracy: 0.6102 - val_loss: 1.9344 - val_accuracy: 0.5042\n",
            "Epoch 4/200\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.9971 - accuracy: 0.6501 - val_loss: 1.8886 - val_accuracy: 0.4888\n",
            "Epoch 5/200\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.9064 - accuracy: 0.6832 - val_loss: 1.0495 - val_accuracy: 0.6605\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.8186 - accuracy: 0.7159 - val_loss: 1.0370 - val_accuracy: 0.6750\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.7623 - accuracy: 0.7362 - val_loss: 0.9400 - val_accuracy: 0.6974\n",
            "Epoch 8/200\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.7318 - accuracy: 0.7477 - val_loss: 0.9310 - val_accuracy: 0.6977\n",
            "Epoch 9/200\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.6780 - accuracy: 0.7661 - val_loss: 1.1702 - val_accuracy: 0.6529\n",
            "Epoch 10/200\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.6504 - accuracy: 0.7762 - val_loss: 0.8486 - val_accuracy: 0.7210\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0009500000451225787.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.6136 - accuracy: 0.7884 - val_loss: 1.2713 - val_accuracy: 0.6410\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0009025000152178108.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.5758 - accuracy: 0.7997 - val_loss: 0.7471 - val_accuracy: 0.7539\n",
            "Epoch 13/200\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0008573750033974647.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.5485 - accuracy: 0.8104 - val_loss: 0.8091 - val_accuracy: 0.7499\n",
            "Epoch 14/200\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0008145062311086804.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.5163 - accuracy: 0.8221 - val_loss: 0.6576 - val_accuracy: 0.7814\n",
            "Epoch 15/200\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0007737808919046074.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.4881 - accuracy: 0.8322 - val_loss: 0.7702 - val_accuracy: 0.7600\n",
            "Epoch 16/200\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.000735091819660738.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.4691 - accuracy: 0.8398 - val_loss: 0.6964 - val_accuracy: 0.7845\n",
            "Epoch 17/200\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0006983372120885178.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.4462 - accuracy: 0.8475 - val_loss: 0.6017 - val_accuracy: 0.8060\n",
            "Epoch 18/200\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0006634203542489559.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.4193 - accuracy: 0.8548 - val_loss: 1.0409 - val_accuracy: 0.7183\n",
            "Epoch 19/200\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0006302493420662358.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.3989 - accuracy: 0.8624 - val_loss: 0.5294 - val_accuracy: 0.8289\n",
            "Epoch 20/200\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0005987368611386045.\n",
            "780/780 [==============================] - 87s 112ms/step - loss: 0.3784 - accuracy: 0.8689 - val_loss: 0.4792 - val_accuracy: 0.8375\n",
            "Epoch 21/200\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0005688000208465382.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.3627 - accuracy: 0.8718 - val_loss: 0.4690 - val_accuracy: 0.8435\n",
            "Epoch 22/200\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.0005403600225690752.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.3530 - accuracy: 0.8787 - val_loss: 0.5163 - val_accuracy: 0.8390\n",
            "Epoch 23/200\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0005133419937919825.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.3265 - accuracy: 0.8866 - val_loss: 0.4221 - val_accuracy: 0.8636\n",
            "Epoch 24/200\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0004876748775132.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.3174 - accuracy: 0.8874 - val_loss: 0.4599 - val_accuracy: 0.8478\n",
            "Epoch 25/200\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.00046329112810781223.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.3033 - accuracy: 0.8960 - val_loss: 0.4157 - val_accuracy: 0.8636\n",
            "Epoch 26/200\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.00044012657308485355.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.2870 - accuracy: 0.9001 - val_loss: 0.4811 - val_accuracy: 0.8471\n",
            "Epoch 27/200\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.00041812024719547477.\n",
            "780/780 [==============================] - 86s 110ms/step - loss: 0.2761 - accuracy: 0.9036 - val_loss: 0.3934 - val_accuracy: 0.8766\n",
            "Epoch 28/200\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.00039721422654110934.\n",
            "780/780 [==============================] - 86s 110ms/step - loss: 0.2668 - accuracy: 0.9068 - val_loss: 0.4006 - val_accuracy: 0.8705\n",
            "Epoch 29/200\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.00037735351797891776.\n",
            "780/780 [==============================] - 86s 110ms/step - loss: 0.2595 - accuracy: 0.9110 - val_loss: 0.4195 - val_accuracy: 0.8702\n",
            "Epoch 30/200\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.00035848583793267607.\n",
            "780/780 [==============================] - 85s 110ms/step - loss: 0.2487 - accuracy: 0.9132 - val_loss: 0.3521 - val_accuracy: 0.8876\n",
            "Epoch 31/200\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.00034056155709549785.\n",
            "780/780 [==============================] - 86s 110ms/step - loss: 0.2416 - accuracy: 0.9153 - val_loss: 0.3712 - val_accuracy: 0.8791\n",
            "Epoch 32/200\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.00032353347924072293.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.2319 - accuracy: 0.9192 - val_loss: 0.3650 - val_accuracy: 0.8828\n",
            "Epoch 33/200\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.00030735681357327847.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.2231 - accuracy: 0.9215 - val_loss: 0.4173 - val_accuracy: 0.8707\n",
            "Epoch 34/200\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.00029198898118920624.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.2199 - accuracy: 0.9216 - val_loss: 0.3253 - val_accuracy: 0.8920\n",
            "Epoch 35/200\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00027738953212974593.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.2050 - accuracy: 0.9264 - val_loss: 0.3239 - val_accuracy: 0.8946\n",
            "Epoch 36/200\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002635200624354184.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.2056 - accuracy: 0.9289 - val_loss: 0.3409 - val_accuracy: 0.8924\n",
            "Epoch 37/200\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002503440482541919.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1973 - accuracy: 0.9324 - val_loss: 0.3569 - val_accuracy: 0.8876\n",
            "Epoch 38/200\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.00023782684584148226.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1770 - accuracy: 0.9369 - val_loss: 0.3316 - val_accuracy: 0.8995\n",
            "Epoch 39/200\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.00022593549801968037.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1788 - accuracy: 0.9387 - val_loss: 0.3243 - val_accuracy: 0.8983\n",
            "Epoch 40/200\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.00021463872035383245.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1741 - accuracy: 0.9381 - val_loss: 0.3025 - val_accuracy: 0.9038\n",
            "Epoch 41/200\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002039067905570846.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1689 - accuracy: 0.9429 - val_loss: 0.3336 - val_accuracy: 0.8980\n",
            "Epoch 42/200\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.00019371145172044634.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.1592 - accuracy: 0.9434 - val_loss: 0.3520 - val_accuracy: 0.8962\n",
            "Epoch 43/200\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.00018402588466415182.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.1543 - accuracy: 0.9448 - val_loss: 0.3462 - val_accuracy: 0.8957\n",
            "Epoch 44/200\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.00017482458351878447.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.1532 - accuracy: 0.9461 - val_loss: 0.3197 - val_accuracy: 0.9013\n",
            "Epoch 45/200\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001660833557252772.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.1438 - accuracy: 0.9501 - val_loss: 0.3217 - val_accuracy: 0.9010\n",
            "Epoch 46/200\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001577791837917175.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1439 - accuracy: 0.9498 - val_loss: 0.2844 - val_accuracy: 0.9122\n",
            "Epoch 47/200\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001498902252933476.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1384 - accuracy: 0.9512 - val_loss: 0.3180 - val_accuracy: 0.9041\n",
            "Epoch 48/200\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.00014239571610232815.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1362 - accuracy: 0.9522 - val_loss: 0.3040 - val_accuracy: 0.9078\n",
            "Epoch 49/200\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.00013527592891477978.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1272 - accuracy: 0.9546 - val_loss: 0.3132 - val_accuracy: 0.9045\n",
            "Epoch 50/200\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.00012851213177782482.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1259 - accuracy: 0.9546 - val_loss: 0.3105 - val_accuracy: 0.9058\n",
            "Epoch 51/200\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.00012208651896798982.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.1223 - accuracy: 0.9571 - val_loss: 0.3195 - val_accuracy: 0.9074\n",
            "Epoch 52/200\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.00011598219716688617.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1201 - accuracy: 0.9581 - val_loss: 0.3115 - val_accuracy: 0.9088\n",
            "Epoch 53/200\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.00011018308869097381.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1177 - accuracy: 0.9597 - val_loss: 0.3222 - val_accuracy: 0.9064\n",
            "Epoch 54/200\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.00010467393149156123.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.1133 - accuracy: 0.9583 - val_loss: 0.3046 - val_accuracy: 0.9100\n",
            "Epoch 55/200\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 9.944023768184706e-05.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1121 - accuracy: 0.9613 - val_loss: 0.2940 - val_accuracy: 0.9105\n",
            "Epoch 56/200\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 9.446822441532275e-05.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.1035 - accuracy: 0.9636 - val_loss: 0.2918 - val_accuracy: 0.9137\n",
            "Epoch 57/200\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 8.974481388577259e-05.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.1042 - accuracy: 0.9637 - val_loss: 0.3035 - val_accuracy: 0.9136\n",
            "Epoch 58/200\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 8.525757111783605e-05.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.1033 - accuracy: 0.9632 - val_loss: 0.3032 - val_accuracy: 0.9138\n",
            "Epoch 59/200\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 8.099469014268834e-05.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.1005 - accuracy: 0.9651 - val_loss: 0.3089 - val_accuracy: 0.9138\n",
            "Epoch 60/200\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 7.694495252508204e-05.\n",
            "780/780 [==============================] - 87s 111ms/step - loss: 0.0998 - accuracy: 0.9656 - val_loss: 0.2946 - val_accuracy: 0.9137\n",
            "Epoch 61/200\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 7.309770662686787e-05.\n",
            "780/780 [==============================] - 87s 112ms/step - loss: 0.0929 - accuracy: 0.9681 - val_loss: 0.3001 - val_accuracy: 0.9153\n",
            "Epoch 62/200\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 6.944281922187656e-05.\n",
            "780/780 [==============================] - 87s 112ms/step - loss: 0.0926 - accuracy: 0.9672 - val_loss: 0.3014 - val_accuracy: 0.9143\n",
            "Epoch 63/200\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 6.597067549591884e-05.\n",
            "780/780 [==============================] - 87s 112ms/step - loss: 0.0902 - accuracy: 0.9680 - val_loss: 0.2980 - val_accuracy: 0.9145\n",
            "Epoch 64/200\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 6.267214448598679e-05.\n",
            "780/780 [==============================] - 87s 112ms/step - loss: 0.0905 - accuracy: 0.9684 - val_loss: 0.3088 - val_accuracy: 0.9120\n",
            "Epoch 65/200\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 5.953853760729544e-05.\n",
            "780/780 [==============================] - 87s 112ms/step - loss: 0.0855 - accuracy: 0.9695 - val_loss: 0.3048 - val_accuracy: 0.9172\n",
            "Epoch 66/200\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 5.656161210936261e-05.\n",
            "780/780 [==============================] - 86s 111ms/step - loss: 0.0888 - accuracy: 0.9684 - val_loss: 0.3003 - val_accuracy: 0.9134\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00066: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Example of creating a ResNet18 model for CIFAR10 dataset\n",
        "model = ResNet50_CIFAR10((32, 32, 3), 10)\n",
        "model.summary()\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.compile(optimizer=SGD(learning_rate=0.01, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 콜백함수\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True)\n",
        "callbacks_list = [early_stopping, lr_scheduler]\n",
        "\n",
        "# steps_per_epoch 설정\n",
        "# 데이터 파이프라인을 통해 2배의 훈련 데아터셋을 학습\n",
        "steps_per_epoch = (len(x_train) // 128) * 2\n",
        "\n",
        "# 모델 훈련\n",
        "history = model.fit(datagen.flow(x_train, y_train_one_hot),\n",
        "                    epochs=200,\n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    validation_data=(x_test, y_test_one_hot),\n",
        "                    shuffle=True,\n",
        "                    callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "C1mQA_JBmqXH",
        "outputId": "9ee37c1f-8661-4bf8-a4e8-137fced40042"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 학습 및 검증 정확도와 손실을 그래프로 표시\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Loss')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# 모델 학습 이후에 이 함수를 호출\n",
        "plot_history(history)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}